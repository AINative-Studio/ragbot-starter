[
  {
    "url": "https://docs.ainative.studio/zerodb/overview",
    "title": "ZeroDB Overview",
    "content": "ZeroDB is AINative Studio's comprehensive intelligent database platform that unifies PostgreSQL, vector databases, and AI-powered data processing. Rather than separate services, ZeroDB provides an integrated ecosystem with advanced capabilities including PostgreSQL foundation with pgvector extension, high-performance vector storage and similarity search, quantum-inspired vector compression and scoring, ML-powered similarity metrics and semantic search, S3-compatible object storage via MinIO, real-time data streaming with RedPanda, and AI agent memory and context management. ZeroDB is production-ready and accessible via the API at https://api.ainative.studio."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/authentication",
    "title": "ZeroDB Authentication",
    "content": "ZeroDB uses two primary authentication methods. First is API Key Authentication which is the recommended approach. You can use it by adding the X-API-Key header to your requests. Second is JWT Bearer Token Authentication where you first login using your email and password to receive an access token, then use that token in the Authorization Bearer header for subsequent requests. To login, make a POST request to /v1/public/auth/login with Content-Type application/x-www-form-urlencoded and body parameters username and password. The response will contain an access_token that expires in 30 minutes."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/embeddings",
    "title": "ZeroDB Embeddings API",
    "content": "The ZeroDB Embeddings API generates 384-dimension vector embeddings using a Railway-hosted HuggingFace embedding service. The model used is BAAI/bge-small-en-v1.5 from HuggingFace, which produces 384-dimensional vectors with performance under 100ms per text. The service is completely FREE as it is self-hosted on Railway. There are three main endpoints: /embeddings/generate for generating embeddings without storing them, /embeddings/embed-and-store for generating embeddings and automatically storing them in your vector database with metadata (recommended for RAG systems), and /embeddings/search for semantic search using natural language queries where the endpoint automatically generates embeddings from your query text and performs similarity search."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/embed-and-store",
    "title": "Embed and Store Endpoint",
    "content": "The embed-and-store endpoint is the recommended approach for building RAG systems with ZeroDB. It combines embedding generation and vector storage in a single API call. To use it, make a POST request to /v1/public/{project_id}/embeddings/embed-and-store with your authentication header. The request body should include a texts array containing the text strings to embed, an optional metadata_list array with metadata for each text, a namespace field (defaults to 'default'), the model name (defaults to BAAI/bge-small-en-v1.5), and the project_id. The response will include success status, the number of vectors stored, embeddings generated, model name, dimensions (384), namespace, and processing time in milliseconds. This endpoint handles both the embedding generation and vector storage, making it very convenient for RAG applications."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/semantic-search",
    "title": "Semantic Search with ZeroDB",
    "content": "ZeroDB's semantic search endpoint allows you to search your vector database using natural language queries. The endpoint automatically generates embeddings from your query text and performs similarity search, so you don't need to manually generate embeddings. To use it, POST to /v1/public/{project_id}/embeddings/search with your query text, project_id, limit for maximum results (default 10, max 100), threshold for similarity threshold (0.0 to 1.0, default 0.7), namespace (default 'default'), optional filter_metadata for filtering results, and model name. The response includes an array of results with the matching text, similarity score, and metadata, along with the query, total results count, model used, and processing time. This is perfect for RAG applications where you want to retrieve relevant context for LLM prompts."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/rag-tutorial",
    "title": "Building RAG Systems with ZeroDB",
    "content": "To build a Retrieval-Augmented Generation system with ZeroDB, follow these steps. First, store your knowledge base documents using the embed-and-store endpoint. Split your documents into chunks (recommended 500-1000 characters), then call the embed-and-store endpoint with your text chunks and metadata. Second, when a user asks a question, use the semantic search endpoint to find relevant context by sending the user's question as the query parameter. The endpoint will automatically embed the query and return similar documents. Third, combine the retrieved context with the user's question and send it to your LLM (like Meta Llama) for generation. ZeroDB handles all the embedding generation automatically, so you don't need external embedding services. The entire flow is: Document -> ZeroDB embed-and-store -> User Question -> ZeroDB semantic search -> Retrieved Context + Question -> LLM -> Answer."
  },
  {
    "url": "https://docs.ainative.studio/meta-llama/overview",
    "title": "Meta Llama Integration",
    "content": "AINative Studio integrates seamlessly with Meta's Llama models for chat completions. Meta Llama provides OpenAI-compatible API endpoints, making it easy to switch from OpenAI to Llama models. The API is available at https://api.llama.com/compat/v1 and supports models like Llama-4-Maverick-17B-128E-Instruct-FP8. To use Meta Llama, you need a Meta API key which starts with 'LLM|'. You can use the OpenAI SDK by simply changing the baseURL to Meta's endpoint and using your Meta API key. This makes it easy to build RAG systems that use ZeroDB for embeddings and retrieval, and Meta Llama for natural language generation."
  },
  {
    "url": "https://docs.ainative.studio/rag/hybrid-approach",
    "title": "Hybrid RAG with ZeroDB and Meta Llama",
    "content": "A hybrid RAG approach combines ZeroDB's embedding and vector search capabilities with Meta Llama's language generation. Here's the recommended architecture: Use ZeroDB's free BAAI/bge-small-en-v1.5 embeddings (384 dimensions) for encoding your documents and queries. This eliminates the need for external embedding services and associated costs. Store your documents in ZeroDB's vector database using the embed-and-store endpoint, which handles both embedding generation and storage in one call. When users ask questions, use ZeroDB's semantic search endpoint to retrieve relevant context. The endpoint automatically embeds the query and finds similar documents. Finally, use Meta Llama's chat completion API with the retrieved context to generate natural language responses. This architecture is cost-effective (free embeddings), simple (no external services needed), and performant (sub-100ms embeddings, fast vector search)."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/vector-operations",
    "title": "Vector Database Operations",
    "content": "ZeroDB provides comprehensive vector database operations. You can upsert vectors individually or in batches using the /vectors/upsert endpoint with a vector_embedding of exactly 1536 dimensions (for compatibility) or 384 dimensions (for BAAI model), along with document text and metadata. Search for similar vectors using the /vectors/search endpoint by providing a query_vector, limit for max results, threshold for similarity cutoff, namespace, and optional metadata filters. The search supports multiple similarity metrics including cosine (default), euclidean, and dot product. You can also delete vectors by ID, retrieve specific vectors, list all vectors with pagination, and get vector statistics for your project. All vector operations are project-isolated, meaning vectors in one project cannot be accessed from another project."
  },
  {
    "url": "https://docs.ainative.studio/zerodb/projects",
    "title": "ZeroDB Project Management",
    "content": "ZeroDB organizes resources using Projects. Each project is an isolated environment with its own database, vectors, tables, and configuration. To create a project, POST to /v1/public/projects with a name, optional description, tier (free, pro, or scale), and database_enabled flag. Projects can be listed, retrieved, updated, and deleted (soft delete by default). You can restore soft-deleted projects or permanently delete them with the hard_delete parameter. Each project has a unique UUID that you use in API calls. Projects provide resource isolation, separate billing, and independent scaling. You can get a summary of all your projects including total counts, usage statistics, and tier distribution using the /projects/stats/summary endpoint."
  },
  {
    "url": "https://docs.ainative.studio/sdk/typescript",
    "title": "AINative TypeScript SDK",
    "content": "The official @ainative/sdk package provides a clean, type-safe interface for interacting with ZeroDB and other AINative services from TypeScript and JavaScript applications. Install it with npm install @ainative/sdk. Initialize the client with your API key and base URL. The SDK provides methods for all ZeroDB operations including vector upsert, search, batch operations, embeddings generation, and project management. It handles authentication, error handling, and provides TypeScript types for all API requests and responses. The SDK is available on NPM and the source code is on GitHub at https://github.com/AINative-Studio/TypeScript-SDK."
  },
  {
    "url": "https://docs.ainative.studio/quickstart",
    "title": "Quick Start Guide",
    "content": "Get started with AINative Studio and ZeroDB in minutes. First, create an account at https://ainative.studio and create a new project in the dashboard. Enable the vector database feature for your project. Copy your API key and project ID from the dashboard. Second, install the SDK with npm install @ainative/sdk for TypeScript/JavaScript or pip install ainative for Python. Third, initialize the client with your credentials. Fourth, store some documents using the embed-and-store endpoint - ZeroDB will automatically generate embeddings. Fifth, search for relevant documents using natural language queries with the semantic search endpoint. Finally, integrate with Meta Llama for chat completions to build a complete RAG system. The entire setup takes less than 10 minutes and requires no external services."
  }
]
